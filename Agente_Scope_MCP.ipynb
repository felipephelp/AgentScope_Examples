{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd16d65d",
   "metadata": {},
   "source": [
    "# Multiagente Extractor (PDF/Imagem)\n",
    "Este módulo cria:\n",
    "- Tools de extração (PDF texto, PDF OCR, Imagem OCR)\n",
    "- Heurística para detectar PDF \"scanned\" (sem texto real)\n",
    "- 3 agentes:\n",
    "  - RouterAgent: decide o caminho (extensão + scanned)\n",
    "  - TextPDF_Agent: tenta extrair texto do PDF\n",
    "  - OCR_Agent: faz OCR (PDF scanned ou imagem)\n",
    "- 1 função `run_extraction(path)` para usar como pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a75c567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: C:\\Users\\fepac\\Unicamp_Project\\dados\n",
      "OK: OUT_DIR = C:\\Users\\fepac\\Unicamp_Project\\dados\\out_extract\n",
      "OK: TRACE_JSONL = C:\\Users\\fepac\\Unicamp_Project\\dados\\out_extract\\trace_log.jsonl\n",
      "OK: TRACE_MD = C:\\Users\\fepac\\Unicamp_Project\\dados\\out_extract\\trace_pretty.md\n"
     ]
    }
   ],
   "source": [
    "# Célula 1 - Inicialização\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "DADOS_DIR = Path(r\"C:\\Users\\fepac\\Unicamp_Project\\dados\")\n",
    "assert DADOS_DIR.exists(), f\"Pasta não existe: {DADOS_DIR}\"\n",
    "print(\"OK:\", DADOS_DIR)\n",
    "\n",
    "OUT_DIR = DADOS_DIR / \"out_extract\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRACE_JSONL = OUT_DIR / \"trace_log.jsonl\"\n",
    "TRACE_MD    = OUT_DIR / \"trace_pretty.md\"\n",
    "\n",
    "# limpa logs\n",
    "for p in [TRACE_JSONL, TRACE_MD]:\n",
    "    if p.exists():\n",
    "        p.unlink()\n",
    "\n",
    "def trace_event(event: Dict[str, Any]) -> None:\n",
    "    event[\"ts\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    TRACE_JSONL.open(\"a\", encoding=\"utf-8\").write(json.dumps(event, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def trace_md(line: str) -> None:\n",
    "    TRACE_MD.open(\"a\", encoding=\"utf-8\").write(line.rstrip() + \"\\n\")\n",
    "\n",
    "print(\"OK: OUT_DIR =\", OUT_DIR)\n",
    "print(\"OK: TRACE_JSONL =\", TRACE_JSONL)\n",
    "print(\"OK: TRACE_MD =\", TRACE_MD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42cbfe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: toolkit pronto\n"
     ]
    }
   ],
   "source": [
    "# Célula 2 - ToolResponse + Toolkit\n",
    "from agentscope.tool import ToolResponse, Toolkit\n",
    "\n",
    "try:\n",
    "    toolkit\n",
    "except NameError:\n",
    "    toolkit = Toolkit()\n",
    "\n",
    "def _resp_text(text: str, **meta) -> ToolResponse:\n",
    "    return ToolResponse(\n",
    "        content=[{\"type\": \"text\", \"text\": text}],\n",
    "        metadata=meta or None,\n",
    "        stream=False,\n",
    "        is_last=True,\n",
    "        is_interrupted=False,\n",
    "        id=None,\n",
    "    )\n",
    "\n",
    "print(\"OK: toolkit pronto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730e6160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: model criado\n",
      "GROQ_BASE_URL: https://api.groq.com/openai/v1\n",
      "GROQ_MODEL: llama-3.3-70b-versatile\n",
      "GROQ_API_KEY prefix: gsk_ len: 56\n"
     ]
    }
   ],
   "source": [
    "# Célula 3 - Model (CORRIGIDA: base_url vai em client_kwargs)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agentscope.model import OpenAIChatModel\n",
    "\n",
    "ENV_PATH = r\"C:\\Users\\fepac\\Unicamp_Project\\.env\"\n",
    "load_dotenv(ENV_PATH, override=True)\n",
    "\n",
    "GROQ_API_KEY  = os.getenv(\"GROQ_API_KEY\")\n",
    "GROQ_BASE_URL = os.getenv(\"GROQ_BASE_URL\", \"https://api.groq.com/openai/v1\")\n",
    "GROQ_MODEL    = os.getenv(\"GROQ_MODEL\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "assert GROQ_API_KEY, \"GROQ_API_KEY não carregou do .env\"\n",
    "assert GROQ_BASE_URL, \"GROQ_BASE_URL não carregou do .env\"\n",
    "\n",
    "model = OpenAIChatModel(\n",
    "    model_name=GROQ_MODEL,\n",
    "    api_key=GROQ_API_KEY,\n",
    "    client_kwargs={\"base_url\": GROQ_BASE_URL},  # <<< FIX DEFINITIVO\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"OK: model criado\")\n",
    "print(\"GROQ_BASE_URL:\", GROQ_BASE_URL)\n",
    "print(\"GROQ_MODEL:\", GROQ_MODEL)\n",
    "print(\"GROQ_API_KEY prefix:\", GROQ_API_KEY[:4], \"len:\", len(GROQ_API_KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8eee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: _pdf_text_stats pronto\n"
     ]
    }
   ],
   "source": [
    "# Célula 4 - Heurística PDF scanned\n",
    "import pdfplumber\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def _pdf_text_stats(pdf_path: str, max_pages: int = 3) -> Dict[str, Any]:\n",
    "    p = Path(pdf_path)\n",
    "    if not p.exists():\n",
    "        return {\"ok\": False, \"error\": \"Arquivo não existe\"}\n",
    "\n",
    "    text_chars = 0\n",
    "    pages_checked = 0\n",
    "    with pdfplumber.open(str(p)) as pdf:\n",
    "        for page in pdf.pages[:max_pages]:\n",
    "            pages_checked += 1\n",
    "            t = page.extract_text() or \"\"\n",
    "            text_chars += len(t.strip())\n",
    "\n",
    "    img_pages = 0\n",
    "    warn = None\n",
    "    try:\n",
    "        reader = PdfReader(str(p))\n",
    "        for i in range(min(max_pages, len(reader.pages))):\n",
    "            page = reader.pages[i]\n",
    "            resources = page.get(\"/Resources\") or {}\n",
    "            xobj = resources.get(\"/XObject\") if hasattr(resources, \"get\") else None\n",
    "            has_img = False\n",
    "            if xobj:\n",
    "                xobj = xobj.get_object()\n",
    "                for _, obj in xobj.items():\n",
    "                    o = obj.get_object()\n",
    "                    if o.get(\"/Subtype\") == \"/Image\":\n",
    "                        has_img = True\n",
    "                        break\n",
    "            if has_img:\n",
    "                img_pages += 1\n",
    "    except Exception as e:\n",
    "        warn = f\"Falha pypdf ao inspecionar imagens: {e}\"\n",
    "\n",
    "    likely_scanned = (text_chars < 50 and img_pages > 0) if warn is None else (text_chars < 50)\n",
    "\n",
    "    return {\n",
    "        \"ok\": True,\n",
    "        \"pages_checked\": pages_checked,\n",
    "        \"text_chars\": text_chars,\n",
    "        \"img_pages\": img_pages if warn is None else None,\n",
    "        \"likely_scanned\": likely_scanned,\n",
    "        \"warn\": warn,\n",
    "    }\n",
    "\n",
    "print(\"OK: _pdf_text_stats pronto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "814be369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: tools PDF registradas\n"
     ]
    }
   ],
   "source": [
    "# Célula 5 - Tools PDF\n",
    "@toolkit.register_tool_function\n",
    "def pdf_is_scanned(pdf_path: str) -> ToolResponse:\n",
    "    trace_event({\"type\": \"tool_start\", \"tool\": \"pdf_is_scanned\", \"pdf_path\": pdf_path})\n",
    "    t0 = time.time()\n",
    "    stats = _pdf_text_stats(pdf_path, max_pages=3)\n",
    "    trace_event({\"type\": \"tool_end\", \"tool\": \"pdf_is_scanned\", \"elapsed_s\": round(time.time()-t0, 3), \"stats\": stats})\n",
    "    trace_md(f\"- tool pdf_is_scanned | {Path(pdf_path).name} | {stats}\")\n",
    "    return _resp_text(str(stats), stats=stats)\n",
    "\n",
    "@toolkit.register_tool_function\n",
    "def extract_pdf_text(pdf_path: str) -> ToolResponse:\n",
    "    trace_event({\"type\": \"tool_start\", \"tool\": \"extract_pdf_text\", \"pdf_path\": pdf_path})\n",
    "    t0 = time.time()\n",
    "\n",
    "    p = Path(pdf_path)\n",
    "    if not p.exists():\n",
    "        trace_event({\"type\": \"tool_end\", \"tool\": \"extract_pdf_text\", \"success\": False, \"error\": \"Arquivo não existe\"})\n",
    "        return _resp_text(\"Arquivo não existe.\", success=False)\n",
    "\n",
    "    texts = []\n",
    "    with pdfplumber.open(str(p)) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            t = page.extract_text() or \"\"\n",
    "            if t.strip():\n",
    "                texts.append(t)\n",
    "\n",
    "    out = \"\\n\\n\".join(texts).strip()\n",
    "    success = bool(out)\n",
    "\n",
    "    trace_event({\"type\": \"tool_end\", \"tool\": \"extract_pdf_text\", \"elapsed_s\": round(time.time()-t0, 3), \"success\": success, \"chars\": len(out)})\n",
    "    trace_md(f\"- tool extract_pdf_text | {p.name} | success={success} chars={len(out)}\")\n",
    "\n",
    "    if not out:\n",
    "        return _resp_text(\"Nenhum texto extraído via pdfplumber.\", success=False)\n",
    "    return _resp_text(out, success=True)\n",
    "\n",
    "print(\"OK: tools PDF registradas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e98fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: tools OCR registradas\n"
     ]
    }
   ],
   "source": [
    "# Célula 6 - Tools OCR\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "TESSERACT_CMD = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"  # ou None\n",
    "TESSDATA_DIR  = Path(r\"C:\\Program Files\\Tesseract-OCR\\tessdata\")\n",
    "DEFAULT_LANG  = \"por\"\n",
    "\n",
    "if TESSERACT_CMD and Path(TESSERACT_CMD).exists():\n",
    "    pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD\n",
    "\n",
    "def _ensure_tess_lang(lang: str, tessdata_dir: Path = TESSDATA_DIR) -> str:\n",
    "    tessdata_dir.mkdir(parents=True, exist_ok=True)\n",
    "    trained = tessdata_dir / f\"{lang}.traineddata\"\n",
    "    if trained.exists():\n",
    "        return lang\n",
    "    if lang == \"por\":\n",
    "        url = \"https://github.com/UB-Mannheim/tesseract/raw/main/tessdata/por.traineddata\"\n",
    "        try:\n",
    "            trace_event({\"type\": \"tess_lang_download_start\", \"lang\": \"por\", \"dest\": str(trained)})\n",
    "            urllib.request.urlretrieve(url, str(trained))\n",
    "            trace_event({\"type\": \"tess_lang_download_end\", \"lang\": \"por\", \"dest\": str(trained), \"success\": True})\n",
    "            return \"por\"\n",
    "        except Exception as e:\n",
    "            trace_event({\"type\": \"tess_lang_download_end\", \"lang\": \"por\", \"dest\": str(trained), \"success\": False, \"error\": str(e)})\n",
    "            return \"eng\"\n",
    "    return \"eng\"\n",
    "\n",
    "@toolkit.register_tool_function\n",
    "def ocr_image(image_path: str, lang: str = DEFAULT_LANG, psm: int = 6, oem: int = 3) -> ToolResponse:\n",
    "    trace_event({\"type\": \"tool_start\", \"tool\": \"ocr_image\", \"image_path\": image_path, \"lang\": lang})\n",
    "    t0 = time.time()\n",
    "\n",
    "    p = Path(image_path)\n",
    "    if not p.exists():\n",
    "        trace_event({\"type\": \"tool_end\", \"tool\": \"ocr_image\", \"success\": False, \"error\": \"Arquivo não existe\"})\n",
    "        return _resp_text(\"Arquivo não existe.\", success=False)\n",
    "\n",
    "    lang_ok = _ensure_tess_lang(lang)\n",
    "    try:\n",
    "        img = Image.open(str(p)).convert(\"RGB\")\n",
    "        cfg = f\"--oem {oem} --psm {psm}\"\n",
    "        text = pytesseract.image_to_string(img, lang=lang_ok, config=cfg).strip()\n",
    "        success = bool(text)\n",
    "\n",
    "        trace_event({\"type\": \"tool_end\", \"tool\": \"ocr_image\", \"elapsed_s\": round(time.time()-t0, 3), \"success\": success, \"lang_used\": lang_ok, \"chars\": len(text)})\n",
    "        trace_md(f\"- tool ocr_image | {p.name} | success={success} lang={lang_ok} chars={len(text)}\")\n",
    "\n",
    "        if not text:\n",
    "            return _resp_text(\"OCR não retornou texto.\", success=False, lang_used=lang_ok)\n",
    "        return _resp_text(text, success=True, lang_used=lang_ok)\n",
    "    except Exception as e:\n",
    "        trace_event({\"type\": \"tool_end\", \"tool\": \"ocr_image\", \"success\": False, \"error\": str(e)})\n",
    "        return _resp_text(f\"Erro no OCR da imagem: {e}\", success=False, lang_used=lang_ok)\n",
    "\n",
    "@toolkit.register_tool_function\n",
    "def ocr_pdf(pdf_path: str, lang: str = DEFAULT_LANG, first_n_pages: int = 5, dpi: int = 250, psm: int = 6, oem: int = 3) -> ToolResponse:\n",
    "    trace_event({\"type\": \"tool_start\", \"tool\": \"ocr_pdf\", \"pdf_path\": pdf_path, \"lang\": lang, \"first_n_pages\": first_n_pages, \"dpi\": dpi})\n",
    "    t0 = time.time()\n",
    "\n",
    "    p = Path(pdf_path)\n",
    "    if not p.exists():\n",
    "        trace_event({\"type\": \"tool_end\", \"tool\": \"ocr_pdf\", \"success\": False, \"error\": \"Arquivo não existe\"})\n",
    "        return _resp_text(\"Arquivo não existe.\", success=False)\n",
    "\n",
    "    lang_ok = _ensure_tess_lang(lang)\n",
    "\n",
    "    try:\n",
    "        pages = convert_from_path(str(p), dpi=dpi, first_page=1, last_page=first_n_pages)\n",
    "    except Exception as e:\n",
    "        trace_event({\"type\": \"tool_end\", \"tool\": \"ocr_pdf\", \"success\": False, \"error\": str(e)})\n",
    "        return _resp_text(\n",
    "            \"Falha ao converter PDF em imagens (pdf2image). Instale Poppler e coloque no PATH. \"\n",
    "            f\"Detalhe: {e}\",\n",
    "            success=False,\n",
    "        )\n",
    "\n",
    "    cfg = f\"--oem {oem} --psm {psm}\"\n",
    "    chunks = []\n",
    "    try:\n",
    "        for i, pil_img in enumerate(pages, start=1):\n",
    "            txt = pytesseract.image_to_string(pil_img.convert('RGB'), lang=lang_ok, config=cfg).strip()\n",
    "            if txt:\n",
    "                chunks.append(f\"--- page {i} ---\\n{txt}\")\n",
    "\n",
    "        out = \"\\n\\n\".join(chunks).strip()\n",
    "        success = bool(out)\n",
    "\n",
    "        trace_event({\"type\": \"tool_end\", \"tool\": \"ocr_pdf\", \"elapsed_s\": round(time.time()-t0, 3), \"success\": success, \"lang_used\": lang_ok, \"pages\": len(pages), \"chars\": len(out)})\n",
    "        trace_md(f\"- tool ocr_pdf | {p.name} | success={success} lang={lang_ok} pages={len(pages)} chars={len(out)}\")\n",
    "\n",
    "        if not out:\n",
    "            return _resp_text(\"OCR no PDF não retornou texto.\", success=False, lang_used=lang_ok)\n",
    "        return _resp_text(out, success=True, lang_used=lang_ok)\n",
    "\n",
    "    except Exception as e:\n",
    "        trace_event({\"type\": \"tool_end\", \"tool\": \"ocr_pdf\", \"success\": False, \"error\": str(e)})\n",
    "        return _resp_text(f\"Erro no OCR do PDF: {e}\", success=False, lang_used=lang_ok)\n",
    "\n",
    "print(\"OK: tools OCR registradas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef0b542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: RouterAgent recriado com OpenAIChatFormatter\n"
     ]
    }
   ],
   "source": [
    "# Célula 7 - RouterAgent (MODIFICADA: troca OpenAIMultiAgentFormatter -> OpenAIChatFormatter)\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.memory import InMemoryMemory\n",
    "from agentscope.formatter import OpenAIChatFormatter  # <<< AQUI\n",
    "from agentscope.tool import ToolResponse\n",
    "\n",
    "formatter = OpenAIChatFormatter()  # <<< AQUI\n",
    "\n",
    "@toolkit.register_tool_function\n",
    "def trace_decision(file_path: str, decision: str, extra: str = \"\") -> ToolResponse:\n",
    "    trace_event({\"type\": \"agent_decision\", \"agent\": \"RouterAgent\", \"file\": file_path, \"decision\": decision, \"extra\": extra})\n",
    "    trace_md(f\"## decision | {Path(file_path).name}\\n- decision: {decision}\\n- extra: {extra}\\n\")\n",
    "    return _resp_text(\"decision logged\", success=True)\n",
    "\n",
    "RouterAgent = ReActAgent(\n",
    "    name=\"RouterAgent\",\n",
    "    sys_prompt=(\n",
    "        \"Você é um roteador de extração.\\n\\n\"\n",
    "        \"Você DEVE seguir este fluxo e registrar decisão chamando a tool trace_decision:\\n\"\n",
    "        \"1) Descubra a extensão do arquivo (use o file_path do usuário).\\n\"\n",
    "        \"2) Se for imagem: chame trace_decision(file_path,'image->ocr_image') e então chame ocr_image.\\n\"\n",
    "        \"3) Se for PDF: chame pdf_is_scanned.\\n\"\n",
    "        \"   - Se likely_scanned=True: chame trace_decision(file_path,'pdf_scanned->ocr_pdf') e então ocr_pdf.\\n\"\n",
    "        \"   - Caso contrário: tente extract_pdf_text.\\n\"\n",
    "        \"       - Se extract_pdf_text retornar success=False: chame trace_decision(file_path,'pdf_text_fail->ocr_pdf') e então ocr_pdf.\\n\"\n",
    "        \"       - Se success=True: chame trace_decision(file_path,'pdf_text->extract_pdf_text').\\n\\n\"\n",
    "        \"Saída: devolva APENAS o texto extraído (sem explicações longas).\"\n",
    "    ),\n",
    "    model=model,\n",
    "    formatter=formatter,\n",
    "    memory=InMemoryMemory(),\n",
    "    toolkit=toolkit,\n",
    "    max_iters=20,\n",
    ")\n",
    "\n",
    "print(\"OK: RouterAgent recriado com OpenAIChatFormatter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e034a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 8 - Batch runner \n",
    "from pathlib import Path\n",
    "from agentscope.message import Msg   # <<< FALTAVA ISSO\n",
    "\n",
    "SUPPORTED_IMAGES = {\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".tif\", \".tiff\"}\n",
    "SUPPORTED_PDFS   = {\".pdf\"}\n",
    "SUPPORTED_EXTS   = SUPPORTED_IMAGES | SUPPORTED_PDFS\n",
    "\n",
    "def list_supported_files(data_dir: Path) -> list[Path]:\n",
    "    return sorted([p for p in data_dir.rglob(\"*\") if p.is_file() and p.suffix.lower() in SUPPORTED_EXTS])\n",
    "\n",
    "def build_extract_msg(file_path: Path, lang: str = \"por\") -> Msg:\n",
    "    return Msg(\n",
    "        name=\"user\",\n",
    "        role=\"user\",\n",
    "        content=(\n",
    "            \"Faça a extração do conteúdo do arquivo abaixo.\\n\"\n",
    "            \"Regras: se for PDF, verifique se é scanned; use OCR quando necessário.\\n\"\n",
    "            f\"Arquivo: {str(file_path)}\\n\"\n",
    "            f\"Lang: {lang}\\n\"\n",
    "            \"Retorne o texto extraído (sem inventar conteúdo).\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "async def extract_one_with_router(file_path: Path, lang: str = \"por\") -> str:\n",
    "    msg = build_extract_msg(file_path, lang=lang)\n",
    "    reply = await RouterAgent.reply(msg)\n",
    "    return reply.get_text_content()\n",
    "\n",
    "async def run_folder_extraction(\n",
    "    data_dir: Path,\n",
    "    out_dir: Path,\n",
    "    lang: str = \"por\",\n",
    "    limit: int = 0,\n",
    ") -> Path:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files = list_supported_files(data_dir)\n",
    "    if limit and limit > 0:\n",
    "        files = files[:limit]\n",
    "\n",
    "    print(f\"Arquivos suportados encontrados: {len(files)}\")\n",
    "    for p in files:\n",
    "        print(\" -\", p.name)\n",
    "\n",
    "    log_rows = [\"file,status,output_or_error\"]\n",
    "    for p in files:\n",
    "        print(\"\\n=== EXTRAINDO:\", p.name, \"===\")\n",
    "        try:\n",
    "            text = await extract_one_with_router(p, lang=lang)\n",
    "            out_txt = out_dir / f\"{p.stem}.txt\"\n",
    "            out_txt.write_text(text, encoding=\"utf-8\", errors=\"ignore\")\n",
    "            log_rows.append(f\"{p.name},OK,{out_txt}\")\n",
    "            print(\"OK ->\", out_txt)\n",
    "        except Exception as e:\n",
    "            log_rows.append(f\"{p.name},ERR,{str(e).replace(',', ';')}\")\n",
    "            print(\"ERRO:\", e)\n",
    "\n",
    "    log_path = out_dir / \"batch_log.csv\"\n",
    "    log_path.write_text(\"\\n\".join(log_rows), encoding=\"utf-8\", errors=\"ignore\")\n",
    "    print(\"\\nLOG salvo em:\", log_path)\n",
    "    return log_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f1f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos suportados encontrados: 2\n",
      " - nota2.png\n",
      " - relatorio_financeiro.pdf\n",
      "\n",
      "=== EXTRAINDO: nota2.png ===\n",
      "ERRO: Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\n",
      "\n",
      "=== EXTRAINDO: relatorio_financeiro.pdf ===\n",
      "RouterAgent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"0j4tyqm4t\",\n",
      "    \"name\": \"trace_decision\",\n",
      "    \"input\": {\n",
      "        \"decision\": \"pdf_scanned->ocr_pdf\",\n",
      "        \"extra\": \"\",\n",
      "        \"file_path\": \"C:\\\\\\\\Users\\\\\\\\fepac\\\\\\\\Unicamp_Project\\\\\\\\dados\\\\\\\\relatorio_financeiro.pdf\"\n",
      "    }\n",
      "}\n",
      "RouterAgent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"jb6xh5hw0\",\n",
      "    \"name\": \"pdf_is_scanned\",\n",
      "    \"input\": {\n",
      "        \"pdf_path\": \"C:\\\\\\\\Users\\\\\\\\fepac\\\\\\\\Unicamp_Project\\\\\\\\dados\\\\\\\\relatorio_financeiro.pdf\"\n",
      "    }\n",
      "}\n",
      "RouterAgent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"sszq0v6rw\",\n",
      "    \"name\": \"ocr_pdf\",\n",
      "    \"input\": {\n",
      "        \"dpi\": 250,\n",
      "        \"first_n_pages\": 5,\n",
      "        \"lang\": \"por\",\n",
      "        \"oem\": 3,\n",
      "        \"pdf_path\": \"C:\\\\\\\\Users\\\\\\\\fepac\\\\\\\\Unicamp_Project\\\\\\\\dados\\\\\\\\relatorio_financeiro.pdf\",\n",
      "        \"psm\": 6\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"0j4tyqm4t\",\n",
      "    \"name\": \"trace_decision\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"decision logged\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"jb6xh5hw0\",\n",
      "    \"name\": \"pdf_is_scanned\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"{'ok': True, 'pages_checked': 1, 'text_chars': 514, 'img_pages': 0, 'likely_scanned': False, 'warn': None}\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"sszq0v6rw\",\n",
      "    \"name\": \"ocr_pdf\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Falha ao converter PDF em imagens (pdf2image). Instale Poppler e coloque no PATH. Detalhe: Unable to get page count. Is poppler installed and in PATH?\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "RouterAgent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"cq06k1k93\",\n",
      "    \"name\": \"trace_decision\",\n",
      "    \"input\": {\n",
      "        \"decision\": \"pdf_text->extract_pdf_text\",\n",
      "        \"extra\": \"\",\n",
      "        \"file_path\": \"C:\\\\\\\\Users\\\\\\\\fepac\\\\\\\\Unicamp_Project\\\\\\\\dados\\\\\\\\relatorio_financeiro.pdf\"\n",
      "    }\n",
      "}\n",
      "RouterAgent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"6ys3nv82t\",\n",
      "    \"name\": \"extract_pdf_text\",\n",
      "    \"input\": {\n",
      "        \"pdf_path\": \"C:\\\\\\\\Users\\\\\\\\fepac\\\\\\\\Unicamp_Project\\\\\\\\dados\\\\\\\\relatorio_financeiro.pdf\"\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"cq06k1k93\",\n",
      "    \"name\": \"trace_decision\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"decision logged\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"6ys3nv82t\",\n",
      "    \"name\": \"extract_pdf_text\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Relatório Financeiro - TechGrow LTDA\\nCNPJ: 12.345.678/0001-90\\nMoeda: BRL\\nLimite de Crédito: 250.000\\nLimite Descoberto: 50.000\\nMeta Saldo Mínimo: 30.000\\nFluxo de Caixa\\nData Entrada Saída Descrição\\n2025-09-01 150000 90000 Receita assinaturas SaaS\\n2025-09-02 20000 25000 Infraestrutura Cloud\\nContas a Pagar\\nFornecedor Valor Vencimento Condição\\nAWS 20000 2025-09-25 30d\\nGoogle Ads 15000 2025-09-28 à vista\\nContas a Receber\\nCliente Valor Vencimento Condição\\nEmpresa X 80000 2025-09-20 30d\\nEmpresa Y 60000 2025-09-30 15d\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "RouterAgent: Relatório Financeiro - TechGrow LTDA\n",
      "CNPJ: 12.345.678/0001-90\n",
      "Moeda: BRL\n",
      "Limite de Crédito: 250.000\n",
      "Limite Descoberto: 50.000\n",
      "Meta Saldo Mínimo: 30.000\n",
      "Fluxo de Caixa\n",
      "Data Entrada Saída Descrição\n",
      "2025-09-01 150000 90000 Receita assinaturas SaaS\n",
      "2025-09-02 20000 25000 Infraestrutura Cloud\n",
      "Contas a Pagar\n",
      "Fornecedor Valor Vencimento Condição\n",
      "AWS 20000 2025-09-25 30d\n",
      "Google Ads 15000 2025-09-28 à vista\n",
      "Contas a Receber\n",
      "Cliente Valor Vencimento Condição\n",
      "Empresa X 80000 2025-09-20 30d\n",
      "Empresa Y 60000 2025-09-30 15d\n",
      "OK -> C:\\Users\\fepac\\Unicamp_Project\\dados\\out_extract\\relatorio_financeiro.txt\n",
      "\n",
      "LOG salvo em: C:\\Users\\fepac\\Unicamp_Project\\dados\\out_extract\\batch_log.csv\n",
      "Finalizado. Log: C:\\Users\\fepac\\Unicamp_Project\\dados\\out_extract\\batch_log.csv\n",
      "Trace JSONL: C:\\Users\\fepac\\Unicamp_Project\\dados\\out_extract\\trace_log.jsonl\n",
      "Trace MD: C:\\Users\\fepac\\Unicamp_Project\\dados\\out_extract\\trace_pretty.md\n"
     ]
    }
   ],
   "source": [
    "# Célula 9 - Executar (Jupyter)\n",
    "log_path = await run_folder_extraction(DADOS_DIR, OUT_DIR, lang=\"por\", limit=0)\n",
    "print(\"Finalizado. Log:\", log_path)\n",
    "print(\"Trace JSONL:\", TRACE_JSONL)\n",
    "print(\"Trace MD:\", TRACE_MD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58763157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY ===\n",
      "\n",
      "relatorio_financeiro.pdf\n",
      "  decisions: ['pdf_scanned->ocr_pdf', 'pdf_text->extract_pdf_text']\n",
      "  tools: []\n",
      "  agent_elapsed: None chars: None\n"
     ]
    }
   ],
   "source": [
    "# Célula 10 - Sumário do trace (por arquivo)\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def summarize_trace(path: Path):\n",
    "    events = []\n",
    "    for ln in path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines():\n",
    "        try:\n",
    "            events.append(json.loads(ln))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    per_file = defaultdict(lambda: {\"decisions\": [], \"tools\": [], \"agent_elapsed\": None, \"chars\": None, \"errors\": []})\n",
    "\n",
    "    for e in events:\n",
    "        f = e.get(\"file\") or e.get(\"pdf_path\") or e.get(\"image_path\")\n",
    "        if not f:\n",
    "            continue\n",
    "        f = str(f)\n",
    "\n",
    "        if e.get(\"type\") == \"agent_decision\":\n",
    "            per_file[f][\"decisions\"].append(e.get(\"decision\"))\n",
    "\n",
    "        if e.get(\"type\") == \"tool_end\":\n",
    "            per_file[f][\"tools\"].append({\n",
    "                \"tool\": e.get(\"tool\"),\n",
    "                \"success\": e.get(\"success\", None),\n",
    "                \"elapsed_s\": e.get(\"elapsed_s\", None),\n",
    "                \"chars\": e.get(\"chars\", None),\n",
    "            })\n",
    "\n",
    "        if e.get(\"type\") == \"agent_call_end\":\n",
    "            per_file[f][\"agent_elapsed\"] = e.get(\"elapsed_s\")\n",
    "            per_file[f][\"chars\"] = e.get(\"chars\")\n",
    "\n",
    "        if e.get(\"type\") in [\"file_error\"]:\n",
    "            per_file[f][\"errors\"].append(e.get(\"error\"))\n",
    "\n",
    "    print(\"=== SUMMARY ===\")\n",
    "    for f, info in per_file.items():\n",
    "        name = Path(f).name\n",
    "        print(f\"\\n{name}\")\n",
    "        print(\"  decisions:\", info[\"decisions\"])\n",
    "        print(\"  tools:\", info[\"tools\"])\n",
    "        print(\"  agent_elapsed:\", info[\"agent_elapsed\"], \"chars:\", info[\"chars\"])\n",
    "        if info[\"errors\"]:\n",
    "            print(\"  errors:\", info[\"errors\"])\n",
    "\n",
    "summarize_trace(TRACE_JSONL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
