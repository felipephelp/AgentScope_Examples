{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0750c1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.13\n"
     ]
    }
   ],
   "source": [
    "import agentscope\n",
    "\n",
    "print(agentscope.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5993d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.message import Msg\n",
    "from agentscope.model import OllamaChatModel\n",
    "from agentscope.formatter import OllamaChatFormatter\n",
    "from agentscope.memory import InMemoryMemory\n",
    "from agentscope.tool import Toolkit, execute_python_code, execute_shell_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4cb21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = Toolkit()\n",
    "toolkit.register_tool_function(execute_python_code)\n",
    "toolkit.register_tool_function(execute_shell_command)\n",
    "\n",
    "agent = ReActAgent(\n",
    "    name=\"Friday\",\n",
    "    sys_prompt=\"You're a helpful assistant named Friday.\",\n",
    "    model=OllamaChatModel(\n",
    "        model_name=\"gpt-oss-safe:latest\",\n",
    "        host=\"http://localhost:11434\",\n",
    "        stream=False,\n",
    "    ),\n",
    "    memory=InMemoryMemory(),\n",
    "    formatter=OllamaChatFormatter(),\n",
    "    toolkit=toolkit,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb3b3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday(thinking): We need to provide Python code for OCR with pytesseract. Should include installation steps, reading image, processing, etc. Provide example. Possibly show how to convert to grayscale, threshold, etc. Also mention need for Tesseract installation. Provide a code snippet. Also maybe include explanation. Should be in Portuguese. Provide code block. Maybe also show how to install packages. We'll provide a script that loads an image from disk, uses pytesseract to read. Provide optional steps. We'll produce a clear answer.\n",
      "Friday: ## OCR simples em Python com **pytesseract**\n",
      "\n",
      "> ‚ö†Ô∏è **Pr√©‚Äërequisitos**  \n",
      "> - Python 3.8+ (pode ser 3.9, 3.10, etc.)  \n",
      "> - Tesseract OCR instalado no seu sistema (n√£o apenas o wrapper Python).  \n",
      ">   - **Linux (Debian/Ubuntu)**: `sudo apt-get install tesseract-ocr`  \n",
      ">   - **macOS**: `brew install tesseract`  \n",
      ">   - **Windows**: Baixe o instalador em https://github.com/UB-Mannheim/tesseract/wiki e, se necess√°rio, adicione o caminho `C:\\Program Files\\Tesseract-OCR` ao `PATH`.  \n",
      "\n",
      "> - Bibliotecas Python:  \n",
      ">   ```bash\n",
      ">   pip install pillow pytesseract opencv-python\n",
      ">   ```\n",
      "\n",
      "### Estrutura do c√≥digo\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "import pytesseract\n",
      "from PIL import Image\n",
      "import numpy as np\n",
      "\n",
      "# 1. (Opcional) Especifique o caminho do execut√°vel tesseract\n",
      "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
      "\n",
      "def preprocess_image(img_path: str, to_grayscale=True, apply_threshold=True) -> np.ndarray:\n",
      "    \"\"\"\n",
      "    Carrega uma imagem, converte para escala de cinza e aplica threshold adaptativo.\n",
      "    Retorna o array numpy que ser√° passado para pytesseract.\n",
      "    \"\"\"\n",
      "    # Carrega a imagem usando OpenCV (BGR)\n",
      "    img = cv2.imread(img_path)\n",
      "\n",
      "    if img is None:\n",
      "        raise FileNotFoundError(f\"Imagem n√£o encontrada: {img_path}\")\n",
      "\n",
      "    # Converter para escala de cinza (se desejado)\n",
      "    if to_grayscale:\n",
      "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    # Aplicar threshold adaptativo para melhorar a legibilidade\n",
      "    if apply_threshold:\n",
      "        img = cv2.adaptiveThreshold(\n",
      "            img,\n",
      "            maxValue=255,\n",
      "            adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
      "            thresholdType=cv2.THRESH_BINARY,\n",
      "            blockSize=31,\n",
      "            C=2\n",
      "        )\n",
      "\n",
      "    return img\n",
      "\n",
      "\n",
      "def ocr_image(img: np.ndarray, lang: str = \"eng\") -> str:\n",
      "    \"\"\"\n",
      "    Executa OCR no array numpy da imagem.\n",
      "    \"\"\"\n",
      "    # Se preferir usar Pillow, converta:\n",
      "    # pil_img = Image.fromarray(img)\n",
      "    # text = pytesseract.image_to_string(pil_img, lang=lang)\n",
      "\n",
      "    # Ou use diretamente o array OpenCV\n",
      "    text = pytesseract.image_to_string(img, lang=lang)\n",
      "\n",
      "    return text\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # Caminho da imagem de entrada\n",
      "    caminho_img = \"caminho/para/sua/imagem.png\"\n",
      "\n",
      "    # Passo 1: pr√©‚Äëprocessar\n",
      "    img_processada = preprocess_image(caminho_img)\n",
      "\n",
      "    # Passo 2: OCR\n",
      "    texto_extraido = ocr_image(img_processada, lang=\"por\")  # \"por\" = portugu√™s\n",
      "\n",
      "    # Exibir resultado\n",
      "    print(\"=== Texto extra√≠do ===\")\n",
      "    print(texto_extraido)\n",
      "```\n",
      "\n",
      "### Explica√ß√£o r√°pida\n",
      "\n",
      "| Etapa | O que acontece | Por que √© importante |\n",
      "|-------|----------------|----------------------|\n",
      "| **Instala√ß√£o do Tesseract** | √â o motor real que faz a leitura | O wrapper `pytesseract` s√≥ encaminha comandos para ele |\n",
      "| **Pr√©‚Äëprocessamento** | Convers√£o para escala de cinza + threshold adaptativo | Remove ru√≠dos, aumenta contraste, melhora a acur√°cia |\n",
      "| **OCR** | `pytesseract.image_to_string` | Executa o algoritmo e devolve o texto |\n",
      "| **Idioma** | `lang=\"por\"` | Indica que o texto est√° em portugu√™s (ou outro, ex.: `\"eng\"`, `\"spa\"`). As l√≠nguas precisam estar instaladas no Tesseract |\n",
      "\n",
      "> üìå **Dica**: Se a sua imagem cont√©m texto em v√°rias fontes ou tem ru√≠do, experimente brincar com `blockSize` e `C` no `adaptiveThreshold` ou use t√©cnicas de remo√ß√£o de ru√≠do (por exemplo, `cv2.medianBlur`).\n",
      "\n",
      "### Como rodar\n",
      "\n",
      "```bash\n",
      "python seu_script.py\n",
      "```\n",
      "\n",
      "Se tudo estiver configurado corretamente, o terminal mostrar√° o texto extra√≠do da imagem.\n",
      "\n",
      "---\n",
      "\n",
      "#### Recursos √∫teis\n",
      "\n",
      "- **Documenta√ß√£o oficial**: https://pypi.org/project/pytesseract/  \n",
      "- **Pacotes de idiomas**: `sudo apt-get install tesseract-ocr-por` (exemplo para portugu√™s em Debian/Ubuntu).  \n",
      "- **Ajustar confian√ßa**: use `pytesseract.image_to_data` para obter confid√™ncia de cada palavra/linha.  \n",
      "\n",
      "Boa sorte com seu OCR! Se precisar de ajustes (por exemplo, OCR em PDF, v√≠deo, ou reconhecimento de tabelas), √© s√≥ avisar.\n",
      "## OCR simples em Python com **pytesseract**\n",
      "\n",
      "> ‚ö†Ô∏è **Pr√©‚Äërequisitos**  \n",
      "> - Python 3.8+ (pode ser 3.9, 3.10, etc.)  \n",
      "> - Tesseract OCR instalado no seu sistema (n√£o apenas o wrapper Python).  \n",
      ">   - **Linux (Debian/Ubuntu)**: `sudo apt-get install tesseract-ocr`  \n",
      ">   - **macOS**: `brew install tesseract`  \n",
      ">   - **Windows**: Baixe o instalador em https://github.com/UB-Mannheim/tesseract/wiki e, se necess√°rio, adicione o caminho `C:\\Program Files\\Tesseract-OCR` ao `PATH`.  \n",
      "\n",
      "> - Bibliotecas Python:  \n",
      ">   ```bash\n",
      ">   pip install pillow pytesseract opencv-python\n",
      ">   ```\n",
      "\n",
      "### Estrutura do c√≥digo\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "import pytesseract\n",
      "from PIL import Image\n",
      "import numpy as np\n",
      "\n",
      "# 1. (Opcional) Especifique o caminho do execut√°vel tesseract\n",
      "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
      "\n",
      "def preprocess_image(img_path: str, to_grayscale=True, apply_threshold=True) -> np.ndarray:\n",
      "    \"\"\"\n",
      "    Carrega uma imagem, converte para escala de cinza e aplica threshold adaptativo.\n",
      "    Retorna o array numpy que ser√° passado para pytesseract.\n",
      "    \"\"\"\n",
      "    # Carrega a imagem usando OpenCV (BGR)\n",
      "    img = cv2.imread(img_path)\n",
      "\n",
      "    if img is None:\n",
      "        raise FileNotFoundError(f\"Imagem n√£o encontrada: {img_path}\")\n",
      "\n",
      "    # Converter para escala de cinza (se desejado)\n",
      "    if to_grayscale:\n",
      "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    # Aplicar threshold adaptativo para melhorar a legibilidade\n",
      "    if apply_threshold:\n",
      "        img = cv2.adaptiveThreshold(\n",
      "            img,\n",
      "            maxValue=255,\n",
      "            adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
      "            thresholdType=cv2.THRESH_BINARY,\n",
      "            blockSize=31,\n",
      "            C=2\n",
      "        )\n",
      "\n",
      "    return img\n",
      "\n",
      "\n",
      "def ocr_image(img: np.ndarray, lang: str = \"eng\") -> str:\n",
      "    \"\"\"\n",
      "    Executa OCR no array numpy da imagem.\n",
      "    \"\"\"\n",
      "    # Se preferir usar Pillow, converta:\n",
      "    # pil_img = Image.fromarray(img)\n",
      "    # text = pytesseract.image_to_string(pil_img, lang=lang)\n",
      "\n",
      "    # Ou use diretamente o array OpenCV\n",
      "    text = pytesseract.image_to_string(img, lang=lang)\n",
      "\n",
      "    return text\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # Caminho da imagem de entrada\n",
      "    caminho_img = \"caminho/para/sua/imagem.png\"\n",
      "\n",
      "    # Passo 1: pr√©‚Äëprocessar\n",
      "    img_processada = preprocess_image(caminho_img)\n",
      "\n",
      "    # Passo 2: OCR\n",
      "    texto_extraido = ocr_image(img_processada, lang=\"por\")  # \"por\" = portugu√™s\n",
      "\n",
      "    # Exibir resultado\n",
      "    print(\"=== Texto extra√≠do ===\")\n",
      "    print(texto_extraido)\n",
      "```\n",
      "\n",
      "### Explica√ß√£o r√°pida\n",
      "\n",
      "| Etapa | O que acontece | Por que √© importante |\n",
      "|-------|----------------|----------------------|\n",
      "| **Instala√ß√£o do Tesseract** | √â o motor real que faz a leitura | O wrapper `pytesseract` s√≥ encaminha comandos para ele |\n",
      "| **Pr√©‚Äëprocessamento** | Convers√£o para escala de cinza + threshold adaptativo | Remove ru√≠dos, aumenta contraste, melhora a acur√°cia |\n",
      "| **OCR** | `pytesseract.image_to_string` | Executa o algoritmo e devolve o texto |\n",
      "| **Idioma** | `lang=\"por\"` | Indica que o texto est√° em portugu√™s (ou outro, ex.: `\"eng\"`, `\"spa\"`). As l√≠nguas precisam estar instaladas no Tesseract |\n",
      "\n",
      "> üìå **Dica**: Se a sua imagem cont√©m texto em v√°rias fontes ou tem ru√≠do, experimente brincar com `blockSize` e `C` no `adaptiveThreshold` ou use t√©cnicas de remo√ß√£o de ru√≠do (por exemplo, `cv2.medianBlur`).\n",
      "\n",
      "### Como rodar\n",
      "\n",
      "```bash\n",
      "python seu_script.py\n",
      "```\n",
      "\n",
      "Se tudo estiver configurado corretamente, o terminal mostrar√° o texto extra√≠do da imagem.\n",
      "\n",
      "---\n",
      "\n",
      "#### Recursos √∫teis\n",
      "\n",
      "- **Documenta√ß√£o oficial**: https://pypi.org/project/pytesseract/  \n",
      "- **Pacotes de idiomas**: `sudo apt-get install tesseract-ocr-por` (exemplo para portugu√™s em Debian/Ubuntu).  \n",
      "- **Ajustar confian√ßa**: use `pytesseract.image_to_data` para obter confid√™ncia de cada palavra/linha.  \n",
      "\n",
      "Boa sorte com seu OCR! Se precisar de ajustes (por exemplo, OCR em PDF, v√≠deo, ou reconhecimento de tabelas), √© s√≥ avisar.\n"
     ]
    }
   ],
   "source": [
    "msg = Msg(\"user\", \"Gere um c√≥digo Python para OCR com pytesseract.\", role=\"user\")\n",
    "reply = await agent(msg)\n",
    "print(reply.get_text_content())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfba8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    agent, user = build_agents()\n",
    "\n",
    "    msg = None\n",
    "    turn = 0\n",
    "    pbar = tqdm(total=0, desc=\"Turns\", unit=\"turn\")\n",
    "\n",
    "    while True:\n",
    "        msg = await agent(msg)\n",
    "        msg = await user(msg)\n",
    "\n",
    "        turn += 1\n",
    "        pbar.total = turn\n",
    "        pbar.update(1)\n",
    "\n",
    "        if msg.get_text_content().strip().lower() == \"exit\":\n",
    "            break\n",
    "\n",
    "    pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807346d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Turns: 0turn [00:00, ?turn/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday(thinking): The user hasn't asked anything yet. We need to wait for the user.\n",
      "Friday: Hello! I'm Friday, your friendly AI assistant. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
